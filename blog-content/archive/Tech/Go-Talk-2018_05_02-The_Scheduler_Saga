The Scheduler Saga
By Kavya Joshi at GopherCon on 2018-05-02

The scheduler is the behind-the-scenes orchestrator of goroutines that use user-space threads (conceptually similar to kernel threads but cheaper and faster to be created) managed by Go runtime. The scheduler multiplexes goroutines onto kernel threads.

Scheduler Goals 1. Use a few kernel threads 2. Support a lot of goroutines 3. Scale to N simultaneous goroutine executions in N-core machine.

Runqueue is a heap-allocated FIFO list containing ready-to-run goroutines.

How to multiplex goroutines onto kernel threads?
Option 1. Multiplex all goroutines on a single thread
- No concurrency and paralellism
Option 2. Create and destroy a thread per goroutine
- Thread is more expensive than goroutine. This therefore defeats the purpose of goroutines.
Option 3. Reuse threads
- Create threads when needed and put them to sleep when idle. But without the limitation, unbounded number of threads can be created.
Option 4. Same as option 3 with additional limitation on threads accessing runqueue
- Syscall threads does not include here. The exact limit should be the number of CPU core. But when performing the experiment, setting #goroutine threads = #CPU cores leads to worse performance than an unmodified Go scheduler. This is caused by contention of threads in the single shared runqueue.
Option 5. Same as option 4 but with distributed runqueues
- With N runqueues on a N-core machine. If the local runqueue is emty, steal work from another runqueue. The handoff mechanism is needed to transfer blocking syscall to a different thread.

Option 5 is the go scheduler.
